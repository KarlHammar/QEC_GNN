{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b9af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric.transforms\n",
    "import torch_geometric.data\n",
    "from torch_geometric.data import Data, ClusterData, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, TopKPooling,GATConv,SAGPooling,LEConv,ASAPooling\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_add\n",
    "from torch.nn import Conv1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa2b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "#dataset = torch.load('graphs_stdc_dmixed.pt')\n",
    "\n",
    "dataset = torch.load('data/d7/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed_large/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed(579)_p1/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/d5p1/graphs_clean.pt')\n",
    "\n",
    "\n",
    "batchsize=128\n",
    "batch_train_splits = int(0.8*len(dataset)/batchsize)*batchsize\n",
    "#batch_val_splits = int(0.2*len(dataset)/batchsize)*batchsize\n",
    "batch_test_splits = int(((len(dataset)-batch_train_splits)/batchsize)*batchsize)\n",
    "#pint(batch_train_splits)\n",
    "#print(batch_test_splits)\n",
    "\n",
    "dataset_usage = len(dataset)-(batch_train_splits+batch_test_splits)\n",
    "\n",
    "if dataset_usage ==0:\n",
    "    train_dataset, test_dataset = random_split(dataset[:],[batch_train_splits, batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "else:\n",
    "    train_dataset, test_dataset = random_split(dataset[:-dataset_usage],[batch_train_splits,batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "#print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5b649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd7c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv_net(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,k,device):\n",
    "        super(GraphConv_net, self).__init__()\n",
    "        \n",
    "        self.conv = GraphConv(2,hidden_channels,aggr='add')\n",
    "        self.conv_1 = GraphConv(hidden_channels,hidden_channels,aggr='add')\n",
    "        \n",
    "        #self.conv = LEConv(2,hidden_channels)\n",
    "        #self.conv_1 = LEConv(hidden_channels,hidden_channels)\n",
    "        \n",
    "        #self.topkpoolX_test = SAGPooling(hidden_channels,ratio=int(k),GNN=GATConv)\n",
    "        #self.topkpoolZ_test = SAGPooling(hidden_channels,ratio=int(k),GNN=GATConv)\n",
    "\n",
    "        #self.topkpoolX = SAGPooling(hidden_channels,ratio=int(k))\n",
    "        #self.topkpoolZ = SAGPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        \n",
    "        \n",
    "        self.topkpoolX_test = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        self.topkpoolZ_test = TopKPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        self.topkpoolX = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        self.topkpoolZ = TopKPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        \n",
    "        self.lin = torch.nn.Linear(2*(hidden_channels*k),48)\n",
    "        self.lin2 = torch.nn.Linear(48,12)\n",
    "        \n",
    "        self.lin_f = torch.nn.Linear(12,1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.drop_out = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = self.conv(x,edge_index,edge_weight=edge_weight)\n",
    "        x = self.tanh(x)\n",
    "        #x = self.conv1(x,edge_index,edge_weight=edge_weight)\n",
    "\n",
    "        x_test, edge_index_xtest, edge_attr_xtest, batch_xtest ,_,_ = self.topkpoolX_test(x,edge_index, batch=batch,edge_attr=edge_weight)\n",
    "        z_test, edge_index_ztest, edge_attr_ztest ,batch_ztest, _,_= self.topkpoolZ_test(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "\n",
    "        x = self.conv_1(x, edge_index, edge_weight=edge_weight)\n",
    "        \n",
    "        \n",
    "        X, edge_index_1, edge_attr_1, batch_1 ,_,_ = self.topkpoolX(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "        Z, edge_index_2, edge_attr_2 ,batch_2, _,_ = self.topkpoolZ(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "\n",
    "\n",
    "        \n",
    "        #print(x_test.shape)\n",
    "        \n",
    "        if x_test.size(0)<(batch_xtest[-1]+1)*self.k:\n",
    "            #missing_dim = (batch_1[-1]+1)*self.k-X.size(0)\n",
    "\n",
    "            old_length_x = 0\n",
    "            for jx in range(batch_xtest[-1]+1):\n",
    "                if jx == batch_xtest[-1]:\n",
    "                    length_x = len(batch_xtest[batch_xtest==jx])\n",
    "                    first_part = x_test[0:length_x+old_length_x, :]\n",
    "                    new_row = torch.zeros(self.k-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    x_test = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_x = len(batch_xtest[batch_xtest==jx])\n",
    "                    first_half = x_test[0:length_x+old_length_x, :]\n",
    "                    second_half = x_test[length_x+old_length_x:, :]\n",
    "                    x_add = torch.zeros(self.k-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    x_test = torch.cat([first_half, x_add, second_half],dim=0)\n",
    "                    \n",
    "                    \n",
    "                    old_length_x += self.k\n",
    "\n",
    "        if z_test.size(0)<(batch_ztest[-1]+1)*self.k:\n",
    "\n",
    "            old_length_z = 0\n",
    "            for kx in range(batch_ztest[-1]+1):\n",
    "                #if Z.size(0) == (batch_2[-1]+1)*self.k:\n",
    "                #    continue\n",
    "                if kx == batch_ztest[-1]:\n",
    "                    length_z = len(batch_ztest[batch_ztest==kx])\n",
    "                    first_part = z_test[0:length_z+old_length_z, :]\n",
    "                    new_row = torch.zeros(self.k-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    z_test = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_z = len(batch_ztest[batch_ztest==kx])\n",
    "                    first_half = z_test[0:length_z+old_length_z, :]\n",
    "                    second_half = z_test[length_z+old_length_z:, :]\n",
    "                    z_add = torch.zeros(self.k-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    z_test = torch.cat([first_half, z_add, second_half],dim=0)\n",
    "                    old_length_z += self.k\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        x_test = torch.flatten(x_test)\n",
    "        z_test = torch.flatten(z_test)\n",
    "        \n",
    "\n",
    "        x_test = x_test.view(batch_xtest[-1]+1,self.hidden_channels*self.k)#self.num_heads*2)\n",
    "        z_test = z_test.view(batch_ztest[-1]+1,self.hidden_channels*self.k)#self.num_heads*2)\n",
    "                \n",
    "        \n",
    "        if X.size(0)<(batch_1[-1]+1)*int(self.k):\n",
    "            #missing_dim = (batch_1[-1]+1)*self.k-X.size(0)\n",
    "\n",
    "            old_length_x = 0\n",
    "            for jx in range(batch_1[-1]+1):\n",
    "                if jx == batch_1[-1]:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_part = X[0:length_x+old_length_x, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_half = X[0:length_x+old_length_x, :]\n",
    "                    second_half = X[length_x+old_length_x:, :]\n",
    "                    x_add = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_half, x_add, second_half],dim=0)\n",
    "                    old_length_x += int(self.k)\n",
    "\n",
    "        if Z.size(0)<(batch_2[-1]+1)*int(self.k):\n",
    "\n",
    "            old_length_z = 0\n",
    "            for kx in range(batch_2[-1]+1):\n",
    "                #if Z.size(0) == (batch_2[-1]+1)*self.k:\n",
    "                #    continue\n",
    "                if kx == batch_2[-1]:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_part = Z[0:length_z+old_length_z, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_half = Z[0:length_z+old_length_z, :]\n",
    "                    second_half = Z[length_z+old_length_z:, :]\n",
    "                    z_add = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_half, z_add, second_half],dim=0)\n",
    "                    old_length_z += int(self.k)\n",
    "        \n",
    "        \n",
    "        X = torch.flatten(X)\n",
    "        Z = torch.flatten(Z)\n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "\n",
    "        X = X.view(batch_1[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        Z = Z.view(batch_2[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        \n",
    "        X = torch.cat([x_test, X], dim=-1)\n",
    "        Z = torch.cat([z_test, Z], dim=-1)\n",
    "        \n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "        \n",
    "        X = self.drop_out(X)\n",
    "        Z = self.drop_out(Z)\n",
    "        \n",
    "        \n",
    "        Z = self.lin(Z)\n",
    "        X = self.lin(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        Z = self.lin2(Z)\n",
    "        X = self.lin2(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        Z = self.lin_f(Z)\n",
    "        X = self.lin_f(X)\n",
    "        \n",
    "\n",
    "        return self.sigmoid(X),self.sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836b8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device =torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2207bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Acc: 0.2955, Train Acc_X: 0.5522, Train Acc_Z: 0.5574, Test Acc: 0.2712\n",
      "Epoch: 010, Train Acc: 0.3000, Train Acc_X: 0.5558, Train Acc_Z: 0.5636, Test Acc: 0.2780\n",
      "Epoch: 015, Train Acc: 0.3221, Train Acc_X: 0.5654, Train Acc_Z: 0.5850, Test Acc: 0.3037\n",
      "Epoch: 020, Train Acc: 0.3395, Train Acc_X: 0.5725, Train Acc_Z: 0.6054, Test Acc: 0.3157\n",
      "Epoch: 025, Train Acc: 0.3799, Train Acc_X: 0.5783, Train Acc_Z: 0.6616, Test Acc: 0.3704\n",
      "Epoch: 030, Train Acc: 0.4074, Train Acc_X: 0.5895, Train Acc_Z: 0.6891, Test Acc: 0.4123\n",
      "Epoch: 035, Train Acc: 0.4295, Train Acc_X: 0.5953, Train Acc_Z: 0.7154, Test Acc: 0.4260\n",
      "Epoch: 040, Train Acc: 0.4348, Train Acc_X: 0.5951, Train Acc_Z: 0.7277, Test Acc: 0.4286\n",
      "Epoch: 045, Train Acc: 0.4424, Train Acc_X: 0.5993, Train Acc_Z: 0.7455, Test Acc: 0.4260\n",
      "Epoch: 050, Train Acc: 0.4694, Train Acc_X: 0.6196, Train Acc_Z: 0.7574, Test Acc: 0.4756\n",
      "Epoch: 055, Train Acc: 0.4873, Train Acc_X: 0.6203, Train Acc_Z: 0.7848, Test Acc: 0.4825\n",
      "Epoch: 060, Train Acc: 0.5252, Train Acc_X: 0.6444, Train Acc_Z: 0.8194, Test Acc: 0.5261\n",
      "Epoch: 065, Train Acc: 0.5699, Train Acc_X: 0.6743, Train Acc_Z: 0.8455, Test Acc: 0.5560\n",
      "Epoch: 070, Train Acc: 0.6176, Train Acc_X: 0.7297, Train Acc_Z: 0.8440, Test Acc: 0.5937\n",
      "Epoch: 075, Train Acc: 0.6679, Train Acc_X: 0.7656, Train Acc_Z: 0.8663, Test Acc: 0.6544\n",
      "Epoch: 080, Train Acc: 0.7051, Train Acc_X: 0.8027, Train Acc_Z: 0.8790, Test Acc: 0.6895\n",
      "Epoch: 085, Train Acc: 0.7382, Train Acc_X: 0.8201, Train Acc_Z: 0.8989, Test Acc: 0.7348\n",
      "Epoch: 090, Train Acc: 0.7705, Train Acc_X: 0.8446, Train Acc_Z: 0.9045, Test Acc: 0.7502\n",
      "Epoch: 095, Train Acc: 0.7607, Train Acc_X: 0.8304, Train Acc_Z: 0.9156, Test Acc: 0.7511\n",
      "Epoch: 100, Train Acc: 0.7897, Train Acc_X: 0.8500, Train Acc_Z: 0.9279, Test Acc: 0.7716\n",
      "Epoch: 105, Train Acc: 0.7882, Train Acc_X: 0.8424, Train Acc_Z: 0.9326, Test Acc: 0.7784\n",
      "Epoch: 110, Train Acc: 0.8250, Train Acc_X: 0.8750, Train Acc_Z: 0.9388, Test Acc: 0.8204\n",
      "Epoch: 115, Train Acc: 0.8404, Train Acc_X: 0.8842, Train Acc_Z: 0.9480, Test Acc: 0.8238\n",
      "Epoch: 120, Train Acc: 0.8993, Train Acc_X: 0.9393, Train Acc_Z: 0.9547, Test Acc: 0.8948\n",
      "Epoch: 125, Train Acc: 0.9103, Train Acc_X: 0.9496, Train Acc_Z: 0.9571, Test Acc: 0.8948\n",
      "Epoch: 130, Train Acc: 0.9270, Train Acc_X: 0.9563, Train Acc_Z: 0.9685, Test Acc: 0.9093\n",
      "Epoch: 135, Train Acc: 0.9219, Train Acc_X: 0.9529, Train Acc_Z: 0.9672, Test Acc: 0.9213\n",
      "Epoch: 140, Train Acc: 0.9333, Train Acc_X: 0.9632, Train Acc_Z: 0.9692, Test Acc: 0.9145\n",
      "Epoch: 145, Train Acc: 0.9368, Train Acc_X: 0.9654, Train Acc_Z: 0.9708, Test Acc: 0.9093\n",
      "Epoch: 150, Train Acc: 0.9353, Train Acc_X: 0.9676, Train Acc_Z: 0.9658, Test Acc: 0.9145\n",
      "Epoch: 155, Train Acc: 0.9408, Train Acc_X: 0.9670, Train Acc_Z: 0.9725, Test Acc: 0.9290\n",
      "Epoch: 160, Train Acc: 0.9420, Train Acc_X: 0.9663, Train Acc_Z: 0.9748, Test Acc: 0.9256\n",
      "Epoch: 165, Train Acc: 0.9478, Train Acc_X: 0.9721, Train Acc_Z: 0.9746, Test Acc: 0.9256\n",
      "Epoch: 170, Train Acc: 0.9469, Train Acc_X: 0.9685, Train Acc_Z: 0.9770, Test Acc: 0.9290\n",
      "Epoch: 175, Train Acc: 0.9563, Train Acc_X: 0.9766, Train Acc_Z: 0.9795, Test Acc: 0.9341\n",
      "Epoch: 180, Train Acc: 0.9496, Train Acc_X: 0.9725, Train Acc_Z: 0.9766, Test Acc: 0.9222\n",
      "Epoch: 185, Train Acc: 0.9587, Train Acc_X: 0.9772, Train Acc_Z: 0.9812, Test Acc: 0.9384\n",
      "Epoch: 190, Train Acc: 0.9567, Train Acc_X: 0.9761, Train Acc_Z: 0.9801, Test Acc: 0.9324\n",
      "Epoch: 195, Train Acc: 0.9574, Train Acc_X: 0.9768, Train Acc_Z: 0.9804, Test Acc: 0.9299\n",
      "Epoch: 200, Train Acc: 0.9596, Train Acc_X: 0.9797, Train Acc_Z: 0.9795, Test Acc: 0.9307\n",
      "Epoch: 205, Train Acc: 0.9616, Train Acc_X: 0.9801, Train Acc_Z: 0.9812, Test Acc: 0.9299\n",
      "Epoch: 210, Train Acc: 0.9594, Train Acc_X: 0.9812, Train Acc_Z: 0.9777, Test Acc: 0.9376\n",
      "Epoch: 215, Train Acc: 0.9710, Train Acc_X: 0.9855, Train Acc_Z: 0.9855, Test Acc: 0.9367\n",
      "Epoch: 220, Train Acc: 0.9708, Train Acc_X: 0.9844, Train Acc_Z: 0.9864, Test Acc: 0.9418\n",
      "Epoch: 225, Train Acc: 0.9725, Train Acc_X: 0.9857, Train Acc_Z: 0.9868, Test Acc: 0.9401\n",
      "Epoch: 230, Train Acc: 0.9708, Train Acc_X: 0.9844, Train Acc_Z: 0.9862, Test Acc: 0.9444\n",
      "Epoch: 235, Train Acc: 0.9690, Train Acc_X: 0.9853, Train Acc_Z: 0.9835, Test Acc: 0.9401\n",
      "Epoch: 240, Train Acc: 0.9737, Train Acc_X: 0.9862, Train Acc_Z: 0.9873, Test Acc: 0.9393\n",
      "Epoch: 245, Train Acc: 0.9739, Train Acc_X: 0.9882, Train Acc_Z: 0.9857, Test Acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "seed =3\n",
    "learning_rate = 0.0025#0.0025 #(0.005)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = GraphConv_net(12,30,device)\n",
    "model.to(device)\n",
    "model = model.double()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.4,patience=10)\n",
    "\n",
    "\n",
    "#criterion = torch.nn.MSELoss().to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss_holder = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        \n",
    "        #int_tar = np.array(idx)\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "    \n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "\n",
    "        #rint(x_target)\n",
    "        #print(z_target)\n",
    "\n",
    "        \n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "        out_X, out_Z = model(data)\n",
    "\n",
    "\n",
    "        loss_X = criterion(out_X, x_target.unsqueeze(-1))# Compute the loss\n",
    "        loss_Z = criterion(out_Z, z_target.unsqueeze(-1))\n",
    "        \n",
    "\n",
    "        loss = sum([loss_X, loss_Z])  # or loss = loss1 + loss2\n",
    "        loss_holder+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()# Update parameters based on gradients.\n",
    "    #acc.append([loss_X.item() ,loss_Z.item()])\n",
    "    loss_item = loss_holder/len(train_loader) \n",
    "    return loss_item\n",
    "    \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct_Z = 0\n",
    "    correct_X = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "\n",
    "        #int_tar = np.array(idx)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "    \n",
    "\n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "\n",
    "        out_X, out_Z = model(data)\n",
    "        #print(out_X, out_Z)\n",
    "        target = torch.cat([x_target.unsqueeze(-1),z_target.unsqueeze(-1)],dim=1)\n",
    "        pred = torch.cat([out_X,out_Z],dim=1)\n",
    "        pred = torch.round(pred)      \n",
    "\n",
    "        correct_X += int((torch.round(out_X)== x_target.unsqueeze(-1)).sum())\n",
    "        correct_Z += int((torch.round(out_Z)== z_target.unsqueeze(-1)).sum())\n",
    "        \n",
    "        for ix in range(len(pred)):\n",
    "            corr=0\n",
    "            corr = int((pred[ix] == target[ix]).sum())  # Check against ground-truth labels.\n",
    "            if corr == 2:\n",
    "                correct =correct+ 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    return correct/len(loader.dataset), correct_X / len(loader.dataset), correct_Z/len(loader.dataset) \n",
    "    \n",
    "\n",
    "\n",
    "train_list = []\n",
    "loss_list = []\n",
    "for epoch in range(1,250):\n",
    "    loss = train()\n",
    "    loss_list.append(loss)\n",
    "    scheduler.step(loss)\n",
    "    train_acc,train_acc_X,train_acc_Z = test(train_loader)\n",
    "    test_acc ,_ ,_ = test(test_loader) \n",
    "    if epoch % 5==0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train Acc_X: {train_acc_X:.4f}, Train Acc_Z: {train_acc_Z:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    train_list.append([train_acc,test_acc,train_acc_X,train_acc_Z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5be655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(loss_list)\n",
    "#ax.plot(b)\n",
    "\n",
    "ax.set(xlabel=\"Epochs\",ylabel=\"Loss\")\n",
    "ax.set(title ='Loss')\n",
    "ax.legend()\n",
    "#plt.savefig('figures/new/model2_bs32_lr002hc14k12_dmixed(57)_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4540d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [train[0] for train in  train_list]\n",
    "b = [train[1] for train in train_list]\n",
    "\n",
    "length = np.zeros(len(train_list))\n",
    "for ix in range(len(train_list)):\n",
    "    length[ix] = ix\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(length,a,label='Train')\n",
    "ax.plot(length,b,label='Test')\n",
    "ax.set(xlabel=\"Epochs\",ylabel=\"Accuracy\")\n",
    "ax.set(title ='GraphConv')\n",
    "ax.legend()\n",
    "#plt.savefig('figures/new/model2_bs32_lr002hc14k12_dmixed(57).pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f1a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"e250_bs32_lr0003_hc24k6_dmixed(579)_clean.pt\"\n",
    "torch.save(model.state_dict(),PATH)\n",
    "#for param_tensor in model.state_dict():\n",
    "#    print(param_tensor, \"\\t\", model.state_dict()[param_tensor])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"e300_bs32_lr0003_hc24k6_largedataset.pt\"\n",
    "#torch.save(model.state_dict(),PATH)\n",
    "#for param_tensor in model.state_dict():\n",
    "#    print(param_tensor, \"\\t\", model.state_dict()[param_tensor])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b545777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0145b67da05c79438d9b05e8abf3e06706409424441d72602b06c6ec46656107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
