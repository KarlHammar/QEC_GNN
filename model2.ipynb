{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric.transforms\n",
    "import torch_geometric.data\n",
    "from torch_geometric.data import Data, ClusterData, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, TopKPooling,GATConv,SAGPooling,LEConv,ASAPooling\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_add\n",
    "from torch.nn import Conv1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = torch.load('graphs_stdc_dmixed.pt')\n",
    "\n",
    "dataset = torch.load('../data/stdc/d7/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed_large/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed(579)_p1/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/d5p1/graphs_clean.pt')\n",
    "\n",
    "\n",
    "batchsize=128\n",
    "batch_train_splits = int(0.8*len(dataset)/batchsize)*batchsize\n",
    "#batch_val_splits = int(0.2*len(dataset)/batchsize)*batchsize\n",
    "batch_test_splits = int(((len(dataset)-batch_train_splits)/batchsize)*batchsize)\n",
    "#pint(batch_train_splits)\n",
    "#print(batch_test_splits)\n",
    "\n",
    "dataset_usage = len(dataset)-(batch_train_splits+batch_test_splits)\n",
    "\n",
    "if dataset_usage ==0:\n",
    "    train_dataset, test_dataset = random_split(dataset[:],[batch_train_splits, batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "else:\n",
    "    train_dataset, test_dataset = random_split(dataset[:-dataset_usage],[batch_train_splits,batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "#print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-costume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv_net(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,k,device):\n",
    "        super(GraphConv_net, self).__init__()\n",
    "        \n",
    "        self.conv = GraphConv(2,hidden_channels,aggr='add')\n",
    "        self.conv_1 = GraphConv(hidden_channels,hidden_channels,aggr='add')\n",
    "        \n",
    "        #self.conv = LEConv(2,hidden_channels)\n",
    "        #self.conv_1 = LEConv(hidden_channels,hidden_channels)\n",
    "        \n",
    "        #self.topkpoolX_test = SAGPooling(hidden_channels,ratio=int(k),GNN=GATConv)\n",
    "        #self.topkpoolZ_test = SAGPooling(hidden_channels,ratio=int(k),GNN=GATConv)\n",
    "\n",
    "        #self.topkpoolX = SAGPooling(hidden_channels,ratio=int(k))\n",
    "        #self.topkpoolZ = SAGPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        \n",
    "        \n",
    "        self.topkpoolX_test = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        self.topkpoolZ_test = TopKPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        self.topkpoolX = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        self.topkpoolZ = TopKPooling(hidden_channels,ratio=int(k))\n",
    "\n",
    "        \n",
    "        self.lin = torch.nn.Linear(2*(hidden_channels*k),48)\n",
    "        self.lin2 = torch.nn.Linear(48,12)\n",
    "        \n",
    "        self.lin_f = torch.nn.Linear(12,1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.drop_out = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = self.conv(x,edge_index,edge_weight=edge_weight)\n",
    "        x = self.tanh(x)\n",
    "        #x = self.conv1(x,edge_index,edge_weight=edge_weight)\n",
    "\n",
    "        x_test, edge_index_xtest, edge_attr_xtest, batch_xtest ,_,_ = self.topkpoolX_test(x,edge_index, batch=batch,edge_attr=edge_weight)\n",
    "        z_test, edge_index_ztest, edge_attr_ztest ,batch_ztest, _,_= self.topkpoolZ_test(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "\n",
    "        x = self.conv_1(x, edge_index, edge_weight=edge_weight)\n",
    "        \n",
    "        \n",
    "        X, edge_index_1, edge_attr_1, batch_1 ,_,_ = self.topkpoolX(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "        Z, edge_index_2, edge_attr_2 ,batch_2, _,_ = self.topkpoolZ(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "\n",
    "\n",
    "        \n",
    "        #print(x_test.shape)\n",
    "        \n",
    "        if x_test.size(0)<(batch_xtest[-1]+1)*self.k:\n",
    "            #missing_dim = (batch_1[-1]+1)*self.k-X.size(0)\n",
    "\n",
    "            old_length_x = 0\n",
    "            for jx in range(batch_xtest[-1]+1):\n",
    "                if jx == batch_xtest[-1]:\n",
    "                    length_x = len(batch_xtest[batch_xtest==jx])\n",
    "                    first_part = x_test[0:length_x+old_length_x, :]\n",
    "                    new_row = torch.zeros(self.k-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    x_test = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_x = len(batch_xtest[batch_xtest==jx])\n",
    "                    first_half = x_test[0:length_x+old_length_x, :]\n",
    "                    second_half = x_test[length_x+old_length_x:, :]\n",
    "                    x_add = torch.zeros(self.k-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    x_test = torch.cat([first_half, x_add, second_half],dim=0)\n",
    "                    \n",
    "                    \n",
    "                    old_length_x += self.k\n",
    "\n",
    "        if z_test.size(0)<(batch_ztest[-1]+1)*self.k:\n",
    "\n",
    "            old_length_z = 0\n",
    "            for kx in range(batch_ztest[-1]+1):\n",
    "                #if Z.size(0) == (batch_2[-1]+1)*self.k:\n",
    "                #    continue\n",
    "                if kx == batch_ztest[-1]:\n",
    "                    length_z = len(batch_ztest[batch_ztest==kx])\n",
    "                    first_part = z_test[0:length_z+old_length_z, :]\n",
    "                    new_row = torch.zeros(self.k-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    z_test = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_z = len(batch_ztest[batch_ztest==kx])\n",
    "                    first_half = z_test[0:length_z+old_length_z, :]\n",
    "                    second_half = z_test[length_z+old_length_z:, :]\n",
    "                    z_add = torch.zeros(self.k-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    z_test = torch.cat([first_half, z_add, second_half],dim=0)\n",
    "                    old_length_z += self.k\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        x_test = torch.flatten(x_test)\n",
    "        z_test = torch.flatten(z_test)\n",
    "        \n",
    "\n",
    "        x_test = x_test.view(batch_xtest[-1]+1,self.hidden_channels*self.k)#self.num_heads*2)\n",
    "        z_test = z_test.view(batch_ztest[-1]+1,self.hidden_channels*self.k)#self.num_heads*2)\n",
    "                \n",
    "        \n",
    "        if X.size(0)<(batch_1[-1]+1)*int(self.k):\n",
    "            #missing_dim = (batch_1[-1]+1)*self.k-X.size(0)\n",
    "\n",
    "            old_length_x = 0\n",
    "            for jx in range(batch_1[-1]+1):\n",
    "                if jx == batch_1[-1]:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_part = X[0:length_x+old_length_x, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_half = X[0:length_x+old_length_x, :]\n",
    "                    second_half = X[length_x+old_length_x:, :]\n",
    "                    x_add = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_half, x_add, second_half],dim=0)\n",
    "                    old_length_x += int(self.k)\n",
    "\n",
    "        if Z.size(0)<(batch_2[-1]+1)*int(self.k):\n",
    "\n",
    "            old_length_z = 0\n",
    "            for kx in range(batch_2[-1]+1):\n",
    "                #if Z.size(0) == (batch_2[-1]+1)*self.k:\n",
    "                #    continue\n",
    "                if kx == batch_2[-1]:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_part = Z[0:length_z+old_length_z, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_half = Z[0:length_z+old_length_z, :]\n",
    "                    second_half = Z[length_z+old_length_z:, :]\n",
    "                    z_add = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_half, z_add, second_half],dim=0)\n",
    "                    old_length_z += int(self.k)\n",
    "        \n",
    "        \n",
    "        X = torch.flatten(X)\n",
    "        Z = torch.flatten(Z)\n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "\n",
    "        X = X.view(batch_1[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        Z = Z.view(batch_2[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        \n",
    "        X = torch.cat([x_test, X], dim=-1)\n",
    "        Z = torch.cat([z_test, Z], dim=-1)\n",
    "        \n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "        \n",
    "        X = self.drop_out(X)\n",
    "        Z = self.drop_out(Z)\n",
    "        \n",
    "        \n",
    "        Z = self.lin(Z)\n",
    "        X = self.lin(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        Z = self.lin2(Z)\n",
    "        X = self.lin2(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        Z = self.lin_f(Z)\n",
    "        X = self.lin_f(X)\n",
    "        \n",
    "\n",
    "        return self.sigmoid(X),self.sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =3\n",
    "learning_rate = 0.0025#0.0025 #(0.005)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = GraphConv_net(12,30,device)\n",
    "model.to(device)\n",
    "model = model.double()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.4,patience=10)\n",
    "\n",
    "\n",
    "#criterion = torch.nn.MSELoss().to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss_holder = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        \n",
    "        #int_tar = np.array(idx)\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "    \n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "\n",
    "        #rint(x_target)\n",
    "        #print(z_target)\n",
    "\n",
    "        \n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "        out_X, out_Z = model(data)\n",
    "\n",
    "\n",
    "        loss_X = criterion(out_X, x_target.unsqueeze(-1))# Compute the loss\n",
    "        loss_Z = criterion(out_Z, z_target.unsqueeze(-1))\n",
    "        \n",
    "\n",
    "        loss = sum([loss_X, loss_Z])  # or loss = loss1 + loss2\n",
    "        loss_holder+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()# Update parameters based on gradients.\n",
    "    #acc.append([loss_X.item() ,loss_Z.item()])\n",
    "    loss_item = loss_holder/len(train_loader) \n",
    "    return loss_item\n",
    "    \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct_Z = 0\n",
    "    correct_X = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "\n",
    "        #int_tar = np.array(idx)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "    \n",
    "\n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "\n",
    "        out_X, out_Z = model(data)\n",
    "        #print(out_X, out_Z)\n",
    "        target = torch.cat([x_target.unsqueeze(-1),z_target.unsqueeze(-1)],dim=1)\n",
    "        pred = torch.cat([out_X,out_Z],dim=1)\n",
    "        pred = torch.round(pred)      \n",
    "\n",
    "        correct_X += int((torch.round(out_X)== x_target.unsqueeze(-1)).sum())\n",
    "        correct_Z += int((torch.round(out_Z)== z_target.unsqueeze(-1)).sum())\n",
    "        \n",
    "        for ix in range(len(pred)):\n",
    "            corr=0\n",
    "            corr = int((pred[ix] == target[ix]).sum())  # Check against ground-truth labels.\n",
    "            if corr == 2:\n",
    "                correct =correct+ 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    return correct/len(loader.dataset), correct_X / len(loader.dataset), correct_Z/len(loader.dataset) \n",
    "    \n",
    "\n",
    "\n",
    "train_list = []\n",
    "loss_list = []\n",
    "for epoch in range(1,250):\n",
    "    loss = train()\n",
    "    loss_list.append(loss)\n",
    "    scheduler.step(loss)\n",
    "    train_acc,train_acc_X,train_acc_Z = test(train_loader)\n",
    "    test_acc ,_ ,_ = test(test_loader) \n",
    "    if epoch % 5==0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train Acc_X: {train_acc_X:.4f}, Train Acc_Z: {train_acc_Z:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    train_list.append([train_acc,test_acc,train_acc_X,train_acc_Z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(loss_list)\n",
    "#ax.plot(b)\n",
    "\n",
    "ax.set(xlabel=\"Epochs\",ylabel=\"Loss\")\n",
    "ax.set(title ='Loss')\n",
    "ax.legend()\n",
    "#plt.savefig('figures/new/model2_bs32_lr002hc14k12_dmixed(57)_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [train[0] for train in  train_list]\n",
    "b = [train[1] for train in train_list]\n",
    "\n",
    "length = np.zeros(len(train_list))\n",
    "for ix in range(len(train_list)):\n",
    "    length[ix] = ix\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(length,a,label='Train')\n",
    "ax.plot(length,b,label='Test')\n",
    "ax.set(xlabel=\"Epochs\",ylabel=\"Accuracy\")\n",
    "ax.set(title ='GraphConv')\n",
    "ax.legend()\n",
    "#plt.savefig('figures/new/model2_bs32_lr002hc14k12_dmixed(57).pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-torture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"e250_bs32_lr0003_hc24k6_dmixed(579)_clean.pt\"\n",
    "torch.save(model.state_dict(),PATH)\n",
    "#for param_tensor in model.state_dict():\n",
    "#    print(param_tensor, \"\\t\", model.state_dict()[param_tensor])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"e300_bs32_lr0003_hc24k6_largedataset.pt\"\n",
    "#torch.save(model.state_dict(),PATH)\n",
    "#for param_tensor in model.state_dict():\n",
    "#    print(param_tensor, \"\\t\", model.state_dict()[param_tensor])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-detroit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
