{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric.transforms\n",
    "import torch_geometric.data\n",
    "from torch_geometric.data import Data, ClusterData, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, TopKPooling,GATConv,SAGPooling,LEConv,ASAPooling\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_add\n",
    "from torch.nn import Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load('data/d5/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed_large/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/dmixed(579)_p1/graphs_clean.pt')\n",
    "#dataset = torch.load('../data/stdc/d5p1/graphs_clean.pt')\n",
    "\n",
    "\n",
    "batchsize=64\n",
    "batch_train_splits = int(0.8*len(dataset)/batchsize)*batchsize\n",
    "#batch_val_splits = int(0.2*len(dataset)/batchsize)*batchsize\n",
    "batch_test_splits = int(((len(dataset)-batch_train_splits)/batchsize)*batchsize)\n",
    "#pint(batch_train_splits)\n",
    "#print(batch_test_splits)\n",
    "\n",
    "dataset_usage = len(dataset)-(batch_train_splits+batch_test_splits)\n",
    "\n",
    "if dataset_usage ==0:\n",
    "    train_dataset, test_dataset = random_split(dataset[:],[batch_train_splits,batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "else:\n",
    "    train_dataset, test_dataset = random_split(dataset[:-dataset_usage],[batch_train_splits,batch_test_splits],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "#print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv_net(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,k,device):\n",
    "        super(GraphConv_net, self).__init__()\n",
    "        \n",
    "        self.conv = GraphConv(2,hidden_channels//2,aggr='add')\n",
    "        self.conv_1 = GraphConv(hidden_channels//2,hidden_channels,aggr='add')\n",
    "        \n",
    "        \n",
    "        #self.conv = GraphConv(2,4,aggr='add')\n",
    "        #self.conv = GATConv(2,hidden_channels,heads=6)\n",
    "        \n",
    "        #self.topkpoolX = TopKPooling(hidden_channels*6,ratio=int(k))\n",
    "        #self.topkpoolZ = TopKPooling(hidden_channels*6,ratio=int(k))\n",
    "        \n",
    "        self.topkpoolX = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        self.topkpoolZ = TopKPooling(hidden_channels,ratio=int(k))\n",
    "        \n",
    "        #self.topkpoolX = ASAPooling(hidden_channels,ratio=k,GNN=GraphConv)\n",
    "        #self.topkpoolZ = ASAPooling(hidden_channels,ratio=k,GNN=GraphConv)\n",
    "        \n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_channels*k,48)\n",
    "        self.lin2 = torch.nn.Linear(48,12)\n",
    "        \n",
    "        self.lin_f = torch.nn.Linear(12,1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.drop_out = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = self.conv(x,edge_index, edge_weight=edge_weight)\n",
    "        x = self.tanh(x)\n",
    "        x = self.conv_1(x, edge_index, edge_weight=edge_weight)\n",
    "            \n",
    "        X, edge_index_1, edge_attr_1, batch_1 ,_,_ = self.topkpoolX(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "        Z, edge_index_2, edge_attr_2 ,batch_2 ,_,_ = self.topkpoolZ(x,edge_index, edge_attr=edge_weight, batch=batch)\n",
    "\n",
    "\n",
    "        # Add empty nodes?\n",
    "        \n",
    "        if X.size(0)<(batch_1[-1]+1)*int(self.k):\n",
    "            #missing_dim = (batch_1[-1]+1)*self.k-X.size(0)\n",
    "\n",
    "            old_length_x = 0\n",
    "            for jx in range(batch_1[-1]+1):\n",
    "                if jx == batch[-1]:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_part = X[0:length_x+old_length_x, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_x = len(batch_1[batch_1==jx])\n",
    "                    first_half = X[0:length_x+old_length_x, :]\n",
    "                    second_half = X[length_x+old_length_x:, :]\n",
    "                    x_add = torch.zeros(int(self.k)-length_x, self.hidden_channels,device=device)#*self.num_heads\n",
    "                    X = torch.cat([first_half, x_add, second_half],dim=0)\n",
    "                    old_length_x += int(self.k)\n",
    "\n",
    "        if Z.size(0)<(batch_2[-1]+1)*int(self.k):\n",
    "\n",
    "            old_length_z = 0\n",
    "            for kx in range(batch_2[-1]+1):\n",
    "                #if Z.size(0) == (batch_2[-1]+1)*self.k:\n",
    "                #    continue\n",
    "                if kx == batch_2[-1]:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_part = Z[0:length_z+old_length_z, :]\n",
    "                    new_row = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_part, new_row],dim=0)\n",
    "                else:\n",
    "                    length_z = len(batch_2[batch_2==kx])\n",
    "                    first_half = Z[0:length_z+old_length_z, :]\n",
    "                    second_half = Z[length_z+old_length_z:, :]\n",
    "                    z_add = torch.zeros(int(self.k)-length_z, self.hidden_channels,device=device)#self.num_heads\n",
    "                    Z = torch.cat([first_half, z_add, second_half],dim=0)\n",
    "                    old_length_z += int(self.k)\n",
    "        \n",
    "        \n",
    "        X = torch.flatten(X)\n",
    "        Z = torch.flatten(Z)\n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "\n",
    "        X = X.view(batch_1[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        Z = Z.view(batch_2[-1]+1,self.hidden_channels*int(self.k))#self.num_heads*2)\n",
    "        \n",
    "        \n",
    "        #print(X.shape)\n",
    "        #print(Z.shape)\n",
    "        \n",
    "        X = self.drop_out(X)\n",
    "        Z = self.drop_out(Z)\n",
    "        \n",
    "        \n",
    "        Z = self.lin(Z)\n",
    "        X = self.lin(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        Z = self.lin2(Z)\n",
    "        X = self.lin2(X)\n",
    "        \n",
    "        \n",
    "        Z = self.tanh(Z)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        Z = self.lin_f(Z)\n",
    "        X = self.lin_f(X)\n",
    "        \n",
    "\n",
    "        return self.sigmoid(X),self.sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Acc: 0.2678, Train Acc_X: 0.5382, Train Acc_Z: 0.5269, Test Acc: 0.2744\n",
      "Epoch: 010, Train Acc: 0.2690, Train Acc_X: 0.5430, Train Acc_Z: 0.5267, Test Acc: 0.2788\n",
      "Epoch: 015, Train Acc: 0.2844, Train Acc_X: 0.5483, Train Acc_Z: 0.5353, Test Acc: 0.2761\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d476f0fa4e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc_Z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-d476f0fa4e49>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_Z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m#print(out_X, out_Z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-821aa8cb5550>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopkpoolX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopkpoolZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/nn/pool/topk_pool.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch, attn)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiplier\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiplier\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/nn/pool/topk_pool.py\u001b[0m in \u001b[0;36mtopk\u001b[0;34m(x, ratio, batch, min_score, tol)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         mask = [\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_num_nodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/nn/pool/topk_pool.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         mask = [\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_num_nodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed =4\n",
    "learning_rate = 0.0025#0.0025 #(0.005)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = GraphConv_net(16,10,device)\n",
    "model.to(device)\n",
    "model = model.double()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.4,patience=10)\n",
    "\n",
    "\n",
    "#criterion = torch.nn.MSELoss().to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss_holder = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        \n",
    "        #int_tar = np.array(idx)\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "    \n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "\n",
    "        #rint(x_target)\n",
    "        #print(z_target)\n",
    "\n",
    "        \n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "        out_X, out_Z = model(data)\n",
    "\n",
    "\n",
    "        loss_X = criterion(out_X, x_target.unsqueeze(-1))# Compute the loss\n",
    "        loss_Z = criterion(out_Z, z_target.unsqueeze(-1))\n",
    "        \n",
    "\n",
    "        loss = sum([loss_X, loss_Z])  # or loss = loss1 + loss2\n",
    "        loss_holder+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()# Update parameters based on gradients.\n",
    "    #acc.append([loss_X.item() ,loss_Z.item()])\n",
    "    loss_item = loss_holder/len(train_loader) \n",
    "    return loss_item\n",
    "    \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct_Z = 0\n",
    "    correct_X = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        \n",
    "        tar, idx = torch.max(data.y,dim=1)\n",
    "\n",
    "        #int_tar = np.array(idx)\n",
    "        int_tar = idx.cpu().numpy()\n",
    "        #print(int_tar)\n",
    "        bin_tar = ((int_tar.reshape(-1,1) & (2**np.arange(2))) != 0).astype(int)\n",
    "        bin_target = bin_tar[:,::-1]\n",
    "        #print(bin_target)\n",
    "        x_target = bin_target[:,0]\n",
    "        z_target = bin_target[:,1]\n",
    "    \n",
    "\n",
    "        x_target = torch.from_numpy(x_target.copy()).double().to(device)\n",
    "        z_target = torch.from_numpy(z_target.copy()).double().to(device)\n",
    "\n",
    "    \n",
    "\n",
    "        out_X, out_Z = model(data)\n",
    "        #print(out_X, out_Z)\n",
    "        target = torch.cat([x_target.unsqueeze(-1),z_target.unsqueeze(-1)],dim=1)\n",
    "        pred = torch.cat([out_X,out_Z],dim=1)\n",
    "        pred = torch.round(pred)      \n",
    "\n",
    "        correct_X += int((torch.round(out_X)== x_target.unsqueeze(-1)).sum())\n",
    "        correct_Z += int((torch.round(out_Z)== z_target.unsqueeze(-1)).sum())\n",
    "        \n",
    "        for ix in range(len(pred)):\n",
    "            corr=0\n",
    "            corr = int((pred[ix] == target[ix]).sum())  # Check against ground-truth labels.\n",
    "            if corr == 2:\n",
    "                correct =correct+ 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    return correct/len(loader.dataset), correct_X / len(loader.dataset), correct_Z/len(loader.dataset) \n",
    "    \n",
    "\n",
    "\n",
    "train_list = []\n",
    "loss_list = []\n",
    "for epoch in range(1,250):\n",
    "    loss = train()\n",
    "    loss_list.append(loss)\n",
    "    scheduler.step(loss)\n",
    "    train_acc,train_acc_X,train_acc_Z = test(train_loader)\n",
    "    test_acc ,_ ,_ = test(test_loader) \n",
    "    if epoch % 5==0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train Acc_X: {train_acc_X:.4f}, Train Acc_Z: {train_acc_Z:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    train_list.append([train_acc,test_acc,train_acc_X,train_acc_Z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model1_e250_bs32_lr0003_hc16k10_d5_clean.pt\"\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0145b67da05c79438d9b05e8abf3e06706409424441d72602b06c6ec46656107"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('gnn': conda)",
   "name": "python3810jvsc74a57bd00145b67da05c79438d9b05e8abf3e06706409424441d72602b06c6ec46656107"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}