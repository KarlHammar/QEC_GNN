{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nasty-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "#Load syndrome matrices and the corresponding eq_class\n",
    "\n",
    "pickle_in2 = open(\"MCMC/MCMC-QEC-toric-RL/defect_matrices/s9p1/dict.eq_distr\",\"rb\")\n",
    "pickle_in1 = open(\"MCMC/MCMC-QEC-toric-RL/defect_matrices/s9p1/dict.defects\",\"rb\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pickle_in2 = open(\"MCMC/MCMC-QEC-toric-RL/defect_matrices/s5p05MWPM/few/dict.eq_distr_stdc\",\"rb\")\n",
    "#pickle_in1 = open(\"MCMC/MCMC-QEC-toric-RL/defect_matrices/s5p05MWPM/few/dict.defects_stdc\",\"rb\")\n",
    "\n",
    "defects = []\n",
    "eq_distr = []\n",
    "counter = 0\n",
    "\n",
    "while 1:\n",
    "    try:\n",
    "        eq_distribution = pickle.load(pickle_in2)\n",
    "        #my_rounded_list = [ round(elem*0.01) for elem in eq_distribution ]\n",
    "        \n",
    "        defects.append(pickle.load(pickle_in1))\n",
    "        eq_distr.append(eq_distribution)\n",
    "\n",
    "        \n",
    "        \n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "\n",
    "print(len(defects))\n",
    "print(len(eq_distr))\n",
    "\n",
    "#print(len(defects1))\n",
    "#print(len(eq_distr1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-review",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacterial-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_defect_matrices(qubit_matrix,size):\n",
    "    #combining the vertex- and plaquette defect matrices\n",
    "    a = np.array(qubit_matrix[0])\n",
    "    b = np.array(qubit_matrix[1])\n",
    "    #print(a)\n",
    "    #print(b)\n",
    "    \n",
    "    a_reshaped = np.zeros((size,size))\n",
    "    b_reshaped = np.zeros((size,size))\n",
    "\n",
    "    a_reshaped[:a.shape[0],:a.shape[1]] = a\n",
    "    b_reshaped[:b.shape[0],:b.shape[1]] = b\n",
    "\n",
    "    for ix in range(size-1):\n",
    "        if ix ==0:\n",
    "            a_reshaped = np.insert(a_reshaped,ix+1,0,axis=1)\n",
    "            a_reshaped = np.insert(a_reshaped,ix,0,axis=0)\n",
    "        \n",
    "            b_reshaped = np.insert(b_reshaped,ix,0,axis=1)\n",
    "            b_reshaped = np.insert(b_reshaped,ix+1,0,axis=0)\n",
    "        else:\n",
    "            a_reshaped = np.insert(a_reshaped,(ix*2)+1,0,axis=1)\n",
    "            a_reshaped = np.insert(a_reshaped,ix*2,0,axis=0)\n",
    "        \n",
    "            b_reshaped = np.insert(b_reshaped,ix*2,0,axis=1)\n",
    "            b_reshaped = np.insert(b_reshaped,(ix*2)+1,0,axis=0)\n",
    "        \n",
    "    combine = a_reshaped+b_reshaped\n",
    "    #print(combine) \n",
    "    return combine\n",
    "\n",
    "def manhattan_dist(positions,nbr_of_defects):\n",
    "    manhattan_distances = np.zeros((nbr_of_defects,nbr_of_defects))\n",
    "    for ix in range(nbr_of_defects):\n",
    "        for jx in range(nbr_of_defects):\n",
    "            if ix == jx:manhattan_distances[ix][jx] = 0\n",
    "            else:\n",
    "                manhattan_distances[ix][jx] = 1/(abs(positions[ix,0]-positions[jx,0])+abs(positions[ix,1]-positions[jx,1]))\n",
    "\n",
    "    return manhattan_distances\n",
    "\n",
    "def distance_to_boundary(combined_matrix,idx,size):\n",
    "    \n",
    "    #size = 5\n",
    "    defect_positions = np.argwhere(combined_matrix)\n",
    "    nbr_of_defects=len(defect_positions)\n",
    "    new_pos= np.zeros((nbr_of_defects,2))\n",
    "    \n",
    "    for ix in range(nbr_of_defects):\n",
    "        if defect_positions[ix][0]%2 == 0 :\n",
    "            aa = defect_positions[ix,1]*0.5\n",
    "            new_pos[ix] = [defect_positions[ix,0]*0.5,aa]\n",
    "        else:\n",
    "            bb = defect_positions[ix,0]*0.5\n",
    "            new_pos[ix] = [bb,defect_positions[ix,1]*0.5]\n",
    "\n",
    "    ##################\n",
    "    #print(new_pos)\n",
    "    manhattan_distances = manhattan_dist(new_pos,nbr_of_defects)\n",
    "    #print(manhattan_distances)\n",
    "    \n",
    "    #from adj.matrix to edgelist\n",
    "    graph = nx.from_numpy_matrix(manhattan_distances)\n",
    "    #edges to be directed both ways\n",
    "    graph = nx.to_directed(graph)\n",
    "    layout= nx.spring_layout(graph)\n",
    "    \n",
    "    ####plot one graph\n",
    "    #if idx == len(defects)-1:\n",
    "        #f = plt.figure()\n",
    "        #nx.draw(graph,ax=f.add_subplot(111),with_labels=True,arrowsize=2, arrowstyle='fancy')\n",
    "        #f.savefig(\"defect_matrices/Graph.png\", format=\"PNG\")\n",
    "    ####\n",
    "\n",
    "    file_2 = open('data/stdc/d9p1/edgelist.txt','ab')        \n",
    "    nx.write_edgelist(graph, file_2)\n",
    "    \n",
    "    #new_line = '\\n'\n",
    "    #file_2.write(new_line.encode('utf-8'))\n",
    "\n",
    "    file_3 = open('data/stdc/d9p1/graph_info.txt','a')        \n",
    "    file_3.write(str(nbr_of_defects)+'\\n')\n",
    "    \n",
    "    #file_2.write(new_line.encode('utf-8'))\n",
    "\n",
    "    \n",
    "    ##################\n",
    "    \n",
    "    order_list_vertex = []\n",
    "    order_list_plaquette = []\n",
    "    for ix in range(nbr_of_defects):\n",
    "        if (round(new_pos[ix,0],2)-int(new_pos[ix,0]) != 0.):\n",
    "            #print(new_pos[ix,0])\n",
    "            order_list_vertex.append(ix)\n",
    "        if (round(new_pos[ix,1],2)-int(new_pos[ix,1]) != 0.):\n",
    "            #print(new_pos[ix,1])\n",
    "            order_list_plaquette.append(ix)\n",
    "\n",
    "    order_array_plaquette = np.array(order_list_plaquette)\n",
    "    order_array_vertex = np.array(order_list_vertex)\n",
    "\n",
    "    #print(len(order_array_plaquette))\n",
    "    #print(len(order_array_vertex))\n",
    "    #print(order_array_vertex)\n",
    "    #print(order_array_plaquette)\n",
    "\n",
    "    #print(new_pos[order_array_vertex])\n",
    "    #print(new_pos[order_array_plaquette])\n",
    "    \n",
    "    ##########\n",
    "    #special case when there are only vertex defects\n",
    "    if len(order_array_plaquette) == 0:\n",
    "        distance_vertex_boundary = np.zeros(len(order_array_vertex))\n",
    "        for ix in range(len(order_array_vertex)):\n",
    "            dist = new_pos[order_array_vertex[ix]]\n",
    "            if dist[0] >= size*0.5:\n",
    "                dist[0] = -(size-dist[0])\n",
    "    \n",
    "            distance_vertex_boundary[ix] = dist[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "        boundary_vertex = np.around(distance_vertex_boundary+0.1)*0.5\n",
    "    \n",
    "        boundary_v = np.ones((len(boundary_vertex),2))\n",
    "        boundary_v = -1*boundary_v\n",
    "        boundary_v[:,0] = boundary_vertex\n",
    "\n",
    "        node_features = np.zeros((nbr_of_defects,2))\n",
    "        node_features[order_array_vertex] = boundary_v\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #special case when there are only plaq. defects\n",
    "    elif len(order_array_vertex) == 0:\n",
    "        distance_plaquette_boundary = np.zeros(len(order_array_plaquette))\n",
    "\n",
    "        for ix in range(len(order_array_plaquette)):\n",
    "            dist = new_pos[order_array_plaquette[ix]]\n",
    "            if dist[1] >= size*0.5:\n",
    "                dist[1] = -(size-dist[1])\n",
    "    \n",
    "            distance_plaquette_boundary[ix] = dist[1]\n",
    "    \n",
    "\n",
    "        boundary_plaquette = np.around(distance_plaquette_boundary+0.1)*0.5\n",
    "\n",
    "    \n",
    "        boundary_p = np.ones((len(boundary_plaquette),2))\n",
    "        boundary_p[:,0] = boundary_plaquette\n",
    "        \n",
    "        \n",
    "        node_features = np.zeros((nbr_of_defects,2))\n",
    "        node_features[order_array_plaquette] = boundary_p\n",
    "        \n",
    "        #print(node_features)\n",
    "    \n",
    "        \n",
    "    ##########\n",
    "    #typical case\n",
    "    else:\n",
    "        distance_vertex_boundary = np.zeros(len(order_array_vertex))\n",
    "        distance_plaquette_boundary = np.zeros(len(order_array_plaquette))\n",
    "\n",
    "        for ix in range(len(order_array_vertex)):\n",
    "            dist = new_pos[order_array_vertex[ix]]\n",
    "            if dist[0] >= size*0.5:#2.5:\n",
    "                dist[0] = -(size-dist[0])\n",
    "    \n",
    "            distance_vertex_boundary[ix] = dist[0]\n",
    "    \n",
    "        for ix in range(len(order_array_plaquette)):\n",
    "            dist = new_pos[order_array_plaquette[ix]]\n",
    "            if dist[1] >= size*0.5:#2.5:\n",
    "                dist[1] = -(size-dist[1])\n",
    "    \n",
    "            distance_plaquette_boundary[ix] = dist[1]\n",
    "    \n",
    "\n",
    "        boundary_vertex = np.around(distance_vertex_boundary+0.1)*0.5\n",
    "        boundary_plaquette = np.around(distance_plaquette_boundary+0.1)*0.5\n",
    "\n",
    "        \n",
    "        boundary_v = np.ones((len(boundary_vertex),2))\n",
    "        boundary_v = -1*boundary_v\n",
    "        boundary_v[:,0] = boundary_vertex\n",
    "\n",
    "        boundary_p = np.ones((len(boundary_plaquette),2))\n",
    "        boundary_p[:,0] = boundary_plaquette\n",
    "    \n",
    "        node_features = np.zeros((nbr_of_defects,2))\n",
    "        node_features[order_array_vertex] = boundary_v\n",
    "        node_features[order_array_plaquette] = boundary_p\n",
    "    \n",
    "    return node_features \n",
    "\n",
    "\n",
    "#caveman function to check balance of classes\n",
    "def conditions(eq_distr,eq_class):\n",
    "    if np.round(eq_distr[0]*0.01) == 1:\n",
    "        eq_class[0] = eq_class[0] + 1\n",
    "    \n",
    "    elif np.round(eq_distr[1]*0.01) == 1:\n",
    "        eq_class[1] = eq_class[1] + 1\n",
    "    \n",
    "    elif np.round(eq_distr[2]*0.01) == 1:\n",
    "        eq_class[2] = eq_class[2] + 1\n",
    "    \n",
    "    else: eq_class[3] = eq_class[3] + 1\n",
    "        \n",
    "    return eq_class\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "martial-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_edge=open('data/stdc/d9p1/node_features.txt','a')\n",
    "pickle_eq_dist = open(\"data/stdc/d9p1/dict.eq_distr\",\"ab\")\n",
    "pickle_defect_matrices = open(\"data/stdc/d9p1/dict.defect\",\"ab\")\n",
    "\n",
    "eq_class_counter = np.zeros(4)\n",
    "\n",
    "zero_def = 0\n",
    "single_def = 0\n",
    "\n",
    "defect_test = []\n",
    "eq_dist_test = []\n",
    "_, size = np.array(defects[0][0]).shape\n",
    "for ix in range(len(defects)):\n",
    "    if (len(np.argwhere(defects[ix][0]))+len(np.argwhere(defects[ix][1]))) == 0:\n",
    "        zero_def +=1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### REMOVE FOR REGULAR RUN, ONLY FOR FEW DEFECT SIM.\n",
    "    #if (len(np.argwhere(defects[ix][0]))+len(np.argwhere(defects[ix][1]))) > 8 :\n",
    "    #    continue\n",
    "    \n",
    "    if (len(np.argwhere(defects[ix][0]))+len(np.argwhere(defects[ix][1]))) == 1:    \n",
    "        single_def +=1\n",
    "        continue\n",
    "    ##################################################\n",
    "    \n",
    "    #the number of syndromes wanted of each class, eg 3500\n",
    "    if np.round(eq_distr[ix][0]*0.01) == 1 and eq_class_counter[0] >= 3500:\n",
    "        continue\n",
    "    if np.round(eq_distr[ix][1]*0.01) == 1 and eq_class_counter[1] >= 3500:\n",
    "        continue\n",
    "    if np.round(eq_distr[ix][2]*0.01) == 1 and eq_class_counter[2] >= 3500:\n",
    "        continue\n",
    "    if np.round(eq_distr[ix][3]*0.01) == 1 and eq_class_counter[3] >= 3500:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    eq_class_counter = conditions(eq_distr[ix],eq_class_counter)\n",
    "    \n",
    "    \n",
    "    \n",
    "    eq_dist_test.append(eq_distr[ix])\n",
    "    pickle.dump(eq_distr[ix],pickle_eq_dist)\n",
    "    pickle.dump(defects[ix],pickle_defect_matrices)\n",
    "    \n",
    "    combined_matrix = combine_defect_matrices(defects[ix],size)\n",
    "    node_features = distance_to_boundary(combined_matrix,ix,size)\n",
    "    #print(node_features)\n",
    "    \n",
    "    np.savetxt(file_edge,node_features,fmt='%.1f')\n",
    "    file_edge.write(\"\\n\")\n",
    "\n",
    "pickle_eq_dist.close()\n",
    "pickle_defect_matrices.close()\n",
    "file_edge.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moving-timer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3500., 3500., 3500., 3436.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_class_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-siemens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-foster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-shell",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-scheduling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-supplement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-neutral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suffering-majority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-device",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-israel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
